{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b288ac47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original corpus :\n",
      "He nodded and , going into the bedroom , brought a needle , thread , and scissors . He said : `` I'm going to bed '' . He nodded at the door in front of him . `` That's my spare bedroom . The bed isn't made , but you'll find plenty of blankets there '' .\n",
      "\n",
      "Tokenized words : \n",
      "['He', 'nodded', 'and', ',', 'going', 'into', 'the', 'bedroom', ',', 'brought', 'a', 'needle', ',', 'thread', ',', 'and', 'scissors', '.', 'He', 'said', ':', '``', 'I', \"'m\", 'going', 'to', 'bed', '``', '.', 'He', 'nodded', 'at', 'the', 'door', 'in', 'front', 'of', 'him', '.', '``', 'That', \"'s\", 'my', 'spare', 'bedroom', '.', 'The', 'bed', 'is', \"n't\", 'made', ',', 'but', 'you', \"'ll\", 'find', 'plenty', 'of', 'blankets', 'there', '``', '.']\n",
      "\n",
      "POS tagged words : \n",
      "[('He', 'PRP'), ('nodded', 'VBD'), ('and', 'CC'), (',', ','), ('going', 'VBG'), ('into', 'IN'), ('the', 'DT'), ('bedroom', 'NN'), (',', ','), ('brought', 'VBD'), ('a', 'DT'), ('needle', 'NN'), (',', ','), ('thread', 'NN'), (',', ','), ('and', 'CC'), ('scissors', 'NNS'), ('.', '.'), ('He', 'PRP'), ('said', 'VBD'), (':', ':'), ('``', '``'), ('I', 'PRP'), (\"'m\", 'VBP'), ('going', 'VBG'), ('to', 'TO'), ('bed', 'VB'), ('``', '``'), ('.', '.'), ('He', 'PRP'), ('nodded', 'VBD'), ('at', 'IN'), ('the', 'DT'), ('door', 'NN'), ('in', 'IN'), ('front', 'NN'), ('of', 'IN'), ('him', 'PRP'), ('.', '.'), ('``', '``'), ('That', 'DT'), (\"'s\", 'VBZ'), ('my', 'PRP$'), ('spare', 'JJ'), ('bedroom', 'NN'), ('.', '.'), ('The', 'DT'), ('bed', 'NN'), ('is', 'VBZ'), (\"n't\", 'RB'), ('made', 'VBN'), (',', ','), ('but', 'CC'), ('you', 'PRP'), (\"'ll\", 'MD'), ('find', 'VB'), ('plenty', 'NN'), ('of', 'IN'), ('blankets', 'NNS'), ('there', 'EX'), ('``', '``'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "from random import choice\n",
    "from nltk import pos_tag\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import brown\n",
    "\n",
    "samples = choice(brown.paras(categories=\"adventure\"))\n",
    "corpus = \" \".join([\" \".join(sample) for sample in samples])\n",
    "print(f\"Original corpus :\\n{corpus}\\n\")\n",
    "\n",
    "tokens = word_tokenize(corpus)\n",
    "print(f\"Tokenized words : \\n{tokens}\\n\")\n",
    "\n",
    "tagged_words = pos_tag(tokens)\n",
    "print(f\"POS tagged words : \\n{tagged_words}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a60ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
