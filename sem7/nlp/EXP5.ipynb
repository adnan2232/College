{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "1b213fb0dd5534ce82d6f1c716e9695ba5cf9758"
   },
   "outputs": [],
   "source": [
    "from nltk.util import pad_sequence\n",
    "from nltk.util import bigrams\n",
    "from nltk.util import ngrams\n",
    "from nltk.util import everygrams\n",
    "from nltk.lm.preprocessing import pad_both_ends\n",
    "from nltk.lm.preprocessing import flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "1c1716261478af5e75bba7799bfefc10bd1ea4ea"
   },
   "outputs": [],
   "source": [
    "text = [['a', 'b', 'c'], ['a', 'c', 'd', 'c', 'e', 'f']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "a5a1c775bab7cf9c67656d4349d8bfca02a80738"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 'b'), ('b', 'c')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(bigrams(text[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "0219988318e39dd0576913b8087af8b35cbdab2f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 'c', 'd'), ('c', 'd', 'c'), ('d', 'c', 'e'), ('c', 'e', 'f')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(text[1], n=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "1ec58c94f58429c9160b4496c939f211f88ade54"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', 'a', 'b', 'c', '</s>']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.util import pad_sequence\n",
    "list(pad_sequence(text[0],\n",
    "                  pad_left=True, left_pad_symbol=\"<s>\",\n",
    "                  pad_right=True, right_pad_symbol=\"</s>\",\n",
    "                  n=2)) # The n order of n-grams, if it's 2-grams, you pad once, 3-grams pad twice, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "ae38644238aa46ac100381c0de046972090b093b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<s>', 'a'), ('a', 'b'), ('b', 'c'), ('c', '</s>')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sent = list(pad_sequence(text[0], pad_left=True, left_pad_symbol=\"<s>\", \n",
    "                                pad_right=True, right_pad_symbol=\"</s>\", n=2))\n",
    "list(ngrams(padded_sent, n=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "4cda3fcbd1b8ab48431240e04168011953ebc913"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', '<s>', 'a', 'b', 'c', '</s>', '</s>']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pad_sequence(text[0],\n",
    "                  pad_left=True, left_pad_symbol=\"<s>\",\n",
    "                  pad_right=True, right_pad_symbol=\"</s>\",\n",
    "                  n=3)) # The n order of n-grams, if it's 2-grams, you pad once, 3-grams pad twice, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "bd572a57371a716471d156144e7ebc136072de01"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<s>', '<s>', 'a'),\n",
       " ('<s>', 'a', 'b'),\n",
       " ('a', 'b', 'c'),\n",
       " ('b', 'c', '</s>'),\n",
       " ('c', '</s>', '</s>')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sent = list(pad_sequence(text[0], pad_left=True, left_pad_symbol=\"<s>\", \n",
    "                                pad_right=True, right_pad_symbol=\"</s>\", n=3))\n",
    "list(ngrams(padded_sent, n=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "eb64c3c2a205c5fc5e1fce6f63c3e9038f0d8c4a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', 'a', 'b', 'c', '</s>']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.lm.preprocessing import pad_both_ends\n",
    "list(pad_both_ends(text[0], n=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2d2581fae73d38d623a77b5d523c957df2dc8478"
   },
   "source": [
    "Combining the two parts discussed so far we get the following preparation steps for one sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "1168917cc340d400f6dba9b2703561785481d8e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<s>', 'a'), ('a', 'b'), ('b', 'c'), ('c', '</s>')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(bigrams(pad_both_ends(text[0], n=2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "dfdc9effca718a7881f1fdc4562cdfb29164b96c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<s>',),\n",
       " ('a',),\n",
       " ('b',),\n",
       " ('c',),\n",
       " ('</s>',),\n",
       " ('<s>', 'a'),\n",
       " ('a', 'b'),\n",
       " ('b', 'c'),\n",
       " ('c', '</s>')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.util import everygrams\n",
    "padded_bigrams = list(pad_both_ends(text[0], n=2))\n",
    "list(everygrams(padded_bigrams, max_len=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "310c937ea7cc847a26f6c3d08c7169e8cd6b354a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', 'a', 'b', 'c', '</s>', '<s>', 'a', 'c', 'd', 'c', 'e', 'f', '</s>']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.lm.preprocessing import flatten\n",
    "list(flatten(pad_both_ends(sent, n=2) for sent in text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "147ccdd961ac97492ee9f0eadf3dfce7325c6790"
   },
   "outputs": [],
   "source": [
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "train, vocab = padded_everygram_pipeline(2, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "aa18a8a4a700926c30488c94cf519d8900de8ddf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('<s>',), ('a',), ('b',), ('c',), ('</s>',), ('<s>', 'a'), ('a', 'b'), ('b', 'c'), ('c', '</s>')]\n",
      "\n",
      "[('<s>',), ('a',), ('c',), ('d',), ('c',), ('e',), ('f',), ('</s>',), ('<s>', 'a'), ('a', 'c'), ('c', 'd'), ('d', 'c'), ('c', 'e'), ('e', 'f'), ('f', '</s>')]\n",
      "\n",
      "#############\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<s>', 'a', 'b', 'c', '</s>', '<s>', 'a', 'c', 'd', 'c', 'e', 'f', '</s>']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_ngrams, padded_sentences = padded_everygram_pipeline(2, text)\n",
    "for ngramlize_sent in training_ngrams:\n",
    "    print(list(ngramlize_sent))\n",
    "    print()\n",
    "print('#############')\n",
    "list(padded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "c679084566e711286d861a622e21ca5c04db7bee"
   },
   "outputs": [],
   "source": [
    "try: \n",
    "    from nltk import word_tokenize, sent_tokenize \n",
    "    word_tokenize(sent_tokenize(\"This is a foobar sentence. Yes it is.\")[0])\n",
    "except:\n",
    "    import re\n",
    "    from nltk.tokenize import ToktokTokenizer\n",
    "    sent_tokenize = lambda x: re.split(r'(?<=[^A-Z].[.?]) +(?=[A-Z])', x)\n",
    "    toktok = ToktokTokenizer()\n",
    "    word_tokenize = word_tokenize = toktok.tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "9bb181f26fb777464b7d4e6d08beac724864cefe"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import io \n",
    "\n",
    "if os.path.isfile('language-never-random.txt'):\n",
    "    with io.open('language-never-random.txt', encoding='utf8') as fin:\n",
    "        text = fin.read()\n",
    "else:\n",
    "    url = \"https://gist.githubusercontent.com/alvations/53b01e4076573fea47c6057120bb017a/raw/b01ff96a5f76848450e648f35da6497ca9454e4a/language-never-random.txt\"\n",
    "    text = requests.get(url).content.decode('utf8')\n",
    "    with io.open('language-never-random.txt', 'w', encoding='utf8') as fout:\n",
    "        fout.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "af4102fcbf643e09319ca6394c175ca64082fd19"
   },
   "outputs": [],
   "source": [
    "\n",
    "tokenized_text = [list(map(str.lower, word_tokenize(sent))) \n",
    "                  for sent in sent_tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "9daa634f65b63882f7192a9489fba198970f3771"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['language',\n",
       " 'is',\n",
       " 'never',\n",
       " ',',\n",
       " 'ever',\n",
       " ',',\n",
       " 'ever',\n",
       " ',',\n",
       " 'random',\n",
       " 'adam',\n",
       " 'kilgarriff',\n",
       " 'abstract',\n",
       " 'language',\n",
       " 'users',\n",
       " 'never',\n",
       " 'choose',\n",
       " 'words',\n",
       " 'randomly',\n",
       " ',',\n",
       " 'and',\n",
       " 'language',\n",
       " 'is',\n",
       " 'essentially',\n",
       " 'non-random',\n",
       " '.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "91c93337cfea53b0c15a6e8617395dab872fb140"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Language is never, ever, ever, random\n",
      "\n",
      "                                                               ADAM KILGARRIFF\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Abstract\n",
      "Language users never choose words randomly, and language is essentially\n",
      "non-random. Statistical hypothesis testing uses a null hypothesis, which\n",
      "posits randomness. Hence, when we look at linguistic phenomena in cor-\n",
      "pora, the null hypothesis will never be true. Moreover, where there is enough\n",
      "data, we shall (almost) always be able to establish \n"
     ]
    }
   ],
   "source": [
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "3eef00b8b1a95043e1c8bdd6912ae22060198e5c"
   },
   "outputs": [],
   "source": [
    "# Preprocess the tokenized text for 3-grams language modelling\n",
    "n = 3\n",
    "train_data, padded_sents = padded_everygram_pipeline(n, tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "2635458b0f3fed618bfae6a0705ccb11555bfb0b"
   },
   "outputs": [],
   "source": [
    "from nltk.lm import MLE\n",
    "model = MLE(n) # Lets train a 3-grams model, previously we set n=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "93b95f89f020585dabfbcd6c41273c823a91e882"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "a31ecc7f6df30a42df9ed6a79039b50f734299cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Vocabulary with cutoff=1 unk_label='<UNK>' and 1391 items>\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_data, padded_sents)\n",
    "print(model.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "6fd7e68c2cdacbe1901fd3b8c05c440706d19100"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1391"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "e5670e34f9d1950f6a1515d57db18092d39484f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('language', 'is', 'never', ',', 'ever', ',', 'ever', ',', 'random', 'adam', 'kilgarriff', 'abstract', 'language', 'users', 'never', 'choose', 'words', 'randomly', ',', 'and', 'language', 'is', 'essentially', 'non-random', '.')\n"
     ]
    }
   ],
   "source": [
    "print(model.vocab.lookup(tokenized_text[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "cfec70768e8976073dda05f702f3f210a33dc1c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('language', 'is', 'never', 'random', '<UNK>', '.')\n"
     ]
    }
   ],
   "source": [
    "# If we lookup the vocab on unseen sentences not from the training data, \n",
    "# it automatically replace words not in the vocabulary with `<UNK>`.\n",
    "print(model.vocab.lookup('language is never random lah .'.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "af5a0851a2f8707ea2e172681342ed3ecd872328"
   },
   "source": [
    "# Using the N-gram Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "bfc60d61539269298390044c0d3415bfd28e2b1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<NgramCounter with 3 ngram orders and 19611 ngrams>\n"
     ]
    }
   ],
   "source": [
    "print(model.counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "90f4611580c41118747a42cfac4c9d729f02523f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.counts['language'] # i.e. Count('language')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "3ba55a83d7c052d1f14923c4046a5f6c86d72c8c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.counts[['language']]['is'] # i.e. Count('is'|'language')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "813e30e1fb153002cfb020d430def2510bf43bbc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.counts[['language', 'is']]['never'] # i.e. Count('never'|'language is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "051ef5a06c004a8e8ddb6168ca318bc8c0c9abf4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003691671588895452"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score('language') # P('language')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "ab3d48919b8f074342e624a1da441621829a4dbd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score('is', 'language'.split())  # P('is'|'language')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "73955908d499f459e19c2cbfaec7d94c513acb91"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6363636363636364"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score('never', 'language is'.split())  # P('never'|'language is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_uuid": "44038e8cd8d078b734a6b1a803d0795517e2fa82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(\"<UNK>\") == model.score(\"lah\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_uuid": "f2f170a0bbca4b33b5eb1a55a55f0e1b1b18a634"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(\"<UNK>\") == model.score(\"leh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_uuid": "9107d1a7c27f30a449e9f370002a6406d5a1396d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(\"<UNK>\") == model.score(\"lor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_uuid": "20ef81b7e161df3b9ab27236c33559713b3077ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6520766965796932"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.logscore(\"never\", \"language is\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "18f9e0a8d0aba302532b8a84f342d1bf4d3e202a"
   },
   "source": [
    "# Generation using N-gram Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_uuid": "98989ec4bae592fc98332e759daf9e42bac4213e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'hence', ',', 'when', 'we', 'look', 'at', 'linguistic', 'phenom-', 'ena', 'in', 'corpora', ',', '216⫺223', '.', '</s>', '</s>', '</s>', '</s>', '</s>']\n"
     ]
    }
   ],
   "source": [
    "print(model.generate(20, random_seed=7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_uuid": "73d0d5e0029e64876100e0f2e368b4835a99efcd"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "\n",
    "detokenize = TreebankWordDetokenizer().detokenize\n",
    "\n",
    "def generate_sent(model, num_words, random_seed=42):\n",
    "    \"\"\"\n",
    "    :param model: An ngram language model from `nltk.lm.model`.\n",
    "    :param num_words: Max no. of words to generate.\n",
    "    :param random_seed: Seed value for random.\n",
    "    \"\"\"\n",
    "    content = []\n",
    "    for token in model.generate(num_words, random_seed=random_seed):\n",
    "        if token == '<s>':\n",
    "            continue\n",
    "        if token == '</s>':\n",
    "            break\n",
    "        content.append(token)\n",
    "    return detokenize(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "_uuid": "949378240cbc8247579b79946b113a3afd039b39"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'and hence, when we look at linguistic phenom- ena in corpora , 216⫺223.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sent(model, 20, random_seed=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "_uuid": "9041c514e0458236132fe9b3c42ac2ce651beb92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'trouble', 'with', 'quantitative', 'studies', '.', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>']\n"
     ]
    }
   ],
   "source": [
    "print(model.generate(28, random_seed=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_uuid": "523e7c2373f6a4c4b6a542f1e82369fedb6cbd21"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the trouble with quantitative studies.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sent(model, 28, random_seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "_uuid": "bce2885bd22d0bb1f79c3861f10fde7df6714e40"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'237⫺246.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sent(model, 20, random_seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "_uuid": "90ddb0e7d0fb52bc77d08425331944c55ee0885e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hypothesis test- ing has been used in the joint conference on empirical methods in nlp and very large corpora although'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sent(model, 20, random_seed=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "_uuid": "ba9546c6800d9e0b0f0af4f0fd31a141af93b12f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'more common or more salient in the last paragraph is ‘ indistinguishable ’.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sent(model, 20, random_seed=42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
