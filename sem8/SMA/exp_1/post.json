{"_default": {"1": {"id": "12glkw4", "author": "TheBodyPolitic1", "author_id": "von3w6y2", "total_comments": 319, "upvote": 591, "post_type": "top week", "title": "Why didn't Python become popular until long after its creation?", "body": "Python was invented in 1994, two years before Java.\n\nGiven it's age, why didn't Python become popular or even widely known about, until much later?", "downvote": 37.72340425531918, "url": "https://www.reddit.com/r/Python/comments/12glkw4/why_didnt_python_become_popular_until_long_after/", "created_on": 1681051909.0, "subreddit": "python", "subreddit_id": "t5_2qh0y"}, "2": {"id": "12hj9oc", "author": "MetonymyQT", "author_id": "shnqm", "total_comments": 80, "upvote": 527, "post_type": "top week", "title": "Free course: Build a modern API with FastAPI and Python", "body": "Hello everyone! \n\nI've posted this course 4 months ago on this sub Reddit and it was well received. I want to do another giveaway,\n\nAll 3 coupons expire in 4 days and allow for a maximum 1k per coupon redeems.\n\n[https://www.udemy.com/course/build-a-movie-tracking-api-with-fastapi-and-python/?couponCode=90707F6B0050F6D60303](https://www.udemy.com/course/build-a-movie-tracking-api-with-fastapi-and-python/?couponCode=90707F6B0050F6D60303)\n\n[https://www.udemy.com/course/build-a-movie-tracking-api-with-fastapi-and-python/?couponCode=F0744D2CC6E3E1C6E622](https://www.udemy.com/course/build-a-movie-tracking-api-with-fastapi-and-python/?couponCode=F0744D2CC6E3E1C6E622)\n\n[https://www.udemy.com/course/build-a-movie-tracking-api-with-fastapi-and-python/?couponCode=A620331B2F48333F76D7](https://www.udemy.com/course/build-a-movie-tracking-api-with-fastapi-and-python/?couponCode=A620331B2F48333F76D7)\n\nI know the course is not top notch and can be improved a lot but honestly I hope you like it as it is. I've set the lowest price I could set for it on Udemy and I'm just grateful that it helped cover my blog hosting fees over the last 3 years.\n\nThank you!", "downvote": 21.958333333333353, "url": "https://www.reddit.com/r/Python/comments/12hj9oc/free_course_build_a_modern_api_with_fastapi_and/", "created_on": 1681134311.0, "subreddit": "python", "subreddit_id": "t5_2qh0y"}, "3": {"id": "12egsoz", "author": "2broke2code", "author_id": "rs4dqilj", "total_comments": 105, "upvote": 467, "post_type": "top week", "title": "I trained a RoastBot on >120,000 faces and >0.5 million comments and it's a menace \ud83d\ude08.", "body": "It uses facial recognition to fetch roasts for users from the r/RoastMe subreddit.\n\nTry it out [here](https://subroast.me)\n\n**App:** [https://subroast.me](https://subroast.me)\n\n**Code:**  [nizarhaider/RoastMe (github.com)](https://github.com/nizarhaider/RoastMe)\n\n# Tech Stack\n\n**Front End:** Bootstrap5 + Vanilla JS\n\n**Back End:** Flask\n\n**CI/CD:** Cloud Build (GCP)\n\n**Deployment:** Cloud Run (GCP)\n\n**Models:** Facenet and MTCNN\n\n&#x200B;\n\n**Edit:**  The entire subreddit has millions of images since 2014 April. I just used a fraction of it. Which means this could be 100x better (or just more accurately racist) given the time and effort to train it.\n\n**Edit2:** At u/Lewis0981 request I've added a 'feature' to see your **match image** (I've seen some bizarre cases of matches so do share them if you get it for a laugh) (Fixed the bug for this)\n\n[RoastMe](https://preview.redd.it/mps1lehexfsa1.png?width=250&format=png&auto=webp&v=enabled&s=e4b2ae973f6ea68e44977bc0c664a68107410616)", "downvote": 35.15053763440857, "url": "https://www.reddit.com/r/Python/comments/12egsoz/i_trained_a_roastbot_on_120000_faces_and_05/", "created_on": 1680863778.0, "subreddit": "python", "subreddit_id": "t5_2qh0y"}, "4": {"id": "12ffsif", "author": "midnitte", "author_id": "3gad9", "total_comments": 64, "upvote": 378, "post_type": "top week", "title": "EP 684: A Per-Interpreter GIL Accepted", "body": "", "downvote": 11.690721649484548, "url": "https://discuss.python.org/t/pep-684-a-per-interpreter-gil/19583/42", "created_on": 1680942397.0, "subreddit": "python", "subreddit_id": "t5_2qh0y"}, "5": {"id": "12fzdu2", "author": "aeluro1", "author_id": "88efmodhn", "total_comments": 12, "upvote": 370, "post_type": "top week", "title": "Comprehensive Reddit Saved Posts Downloader - retrieves almost all content ever saved", "body": "Hi all, I made a post about this a couple of days ago, but I've made some pretty massive changes since then and I wanted to share it again. I'm super happy with the results.\n\nTo recap, this program backs up all of your saved posts on Reddit, obtaining media such as Reddit galleries, Imgur albums, gifs, videos, etc. It stores a local log of all of the files downloaded/skipped.\n\nSince last posting, I've added the ability to load your entire saved post record using information provided by Reddit. However, I noticed that a lot of the content had been deleted or removed, making up about a quarter of all my posts. So now I've implemented the ability to retrieve this information from pushshift and the wayback machine, and it works very well. For reference, I downloaded about 3500 posts from 5+ years back and only had around 200 fail.\n\nLet me know how my code looks and if there's anything I could improve on. Thanks!\n\n[https://github.com/aeluro1/geddit](https://github.com/aeluro1/geddit)", "downvote": 11.443298969072176, "url": "https://www.reddit.com/r/Python/comments/12fzdu2/comprehensive_reddit_saved_posts_downloader/", "created_on": 1680990221.0, "subreddit": "python", "subreddit_id": "t5_2qh0y"}, "6": {"id": "12f3glm", "author": "Flamewire", "author_id": "6rgnq", "total_comments": 94, "upvote": 359, "post_type": "top week", "title": "PEP 695: Type Parameter Syntax has been accepted by the Steering Council", "body": "", "downvote": 11.103092783505165, "url": "https://discuss.python.org/t/pep-695-type-parameter-syntax/21646/92?u=tusharc", "created_on": 1680909848.0, "subreddit": "python", "subreddit_id": "t5_2qh0y"}, "7": {"id": "12ha6mc", "author": "stillreadingit_", "author_id": "8f6n85u", "total_comments": 86, "upvote": 331, "post_type": "top week", "title": "Ruff: one Python linter to rule them all", "body": "", "downvote": 32.73626373626372, "url": "https://blog.jerrycodes.com/ruff-the-python-linter/", "created_on": 1681109913.0, "subreddit": "python", "subreddit_id": "t5_2qh0y"}, "8": {"id": "12dfdq1", "author": "BeingHeldAgainstWill", "author_id": "3brony28", "total_comments": 43, "upvote": 318, "post_type": "top week", "title": "SpotiFile : Music scraping made easy", "body": " \n\nI made a neat tool to scrape songs (with GUI).\n\n[GitHub Link](https://github.com/Michael-K-Stein/SpotiFile)\n\nAll you need to do is install the dependencies (\"pip install -r ./requirements\"), and then \"python [main.py](https://main.py/)\". It's that easy!\n\n##This tool is mainly aimed at developers looking to create datasets to train ML models.\n\nSpotiFile will open a GUI which lets you enter a playlist, album, artist, or user profile link and download all the relevant songs. This will also download all the metadata of the song, including the time-synced lyrics!\n\nIf you use the tool, please give the repo a star :)\nAnd please tell me how to improve the code quality!\n\nEnjoy!", "downvote": 16.736842105263175, "url": "https://www.reddit.com/r/Python/comments/12dfdq1/spotifile_music_scraping_made_easy/", "created_on": 1680775865.0, "subreddit": "python", "subreddit_id": "t5_2qh0y"}, "9": {"id": "12cgplg", "author": "GoLoginS", "author_id": "bagwimeb", "total_comments": 30, "upvote": 315, "post_type": "top week", "title": "Step-by-step tutorial on Web Scraping with Python with code snippets", "body": "", "downvote": 31.153846153846143, "url": "https://gologin.com/blog/web-scraping-with-python", "created_on": 1680693038.0, "subreddit": "python", "subreddit_id": "t5_2qh0y"}, "10": {"id": "12bl2uj", "author": "Ok-Craft-9908", "author_id": "alzl8hco", "total_comments": 24, "upvote": 278, "post_type": "top week", "title": "Analysing the emotion timeline of the Enron scandal through their internal emails in Python", "body": "I've been playing around with the Enron dataset in Python. Thought it would be interesting to you folks.\n\nhttps://reddit.com/link/12bl2uj/video/g2m72xcspvra1/player\n\n&#x200B;\n\nMainly used pandas, using the dataset of internal Enron emails from their collapse that was released during criminal proceedings.\n\nAlso used the NRC Emotion Lexicon.\n\nBlog: [https://www.superflows.ai/blog/enron-sentiment](https://www.superflows.ai/blog/enron-sentiment)\n\n&#x200B;\n\nEdit: sent the wrong repo! \n\nGitHub repo: [https://github.com/SuperflowsAI/enron-sentiment-analysis](https://github.com/SuperflowsAI/enron-sentiment-analysis)", "downvote": 11.583333333333345, "url": "https://www.reddit.com/r/Python/comments/12bl2uj/analysing_the_emotion_timeline_of_the_enron/", "created_on": 1680619070.0, "subreddit": "python", "subreddit_id": "t5_2qh0y"}}}